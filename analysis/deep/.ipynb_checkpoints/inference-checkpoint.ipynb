{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script exemple for inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import models, transforms\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EsthDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, transforms=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.paths[index])\n",
    "        \n",
    "        if image.size[0] != 500 or image.size[1] != 500 :\n",
    "            print(f\"{self.paths[index]} is the wrong size : {image.size}. It has been resized to (500,500) but tha accuracy of the score cannot be guaranteed\")\n",
    "            image = image.resize((500,500))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(index, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters config for the model architecture and data loader\n",
    "\n",
    "# Use GPU or CPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "#Path for the weights of the saved model we want to use\n",
    "#weights_path = './saved_models/1000epochs_survey/Chckpt_ResNet50_-11339.0159.pt'\n",
    "weights_path = './saved_models/1000epochs_survey/Chckpt_ResNet50_-11339.0159.pt'\n",
    "\n",
    "\n",
    "#Path to the input data and output file\n",
    "#in_path = '../data/BIG_FILES/ggstreet/png/'\n",
    "in_path = '../data/BIG_FILES/ggstreet/png_good/'\n",
    "#out_path = '../results/inference_ggstreet_facade.csv'\n",
    "out_path = '../results/inference_ggstreet.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_for_eval(path_to_weights):\n",
    "    \"\"\"Gets the broadcasted model.\"\"\"\n",
    "    model = models.resnet50()\n",
    "    \n",
    "    model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(2048, 1)\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(path_to_weights))\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_batch(paths, path_to_weights, output_path):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.392, 0.298, 0.203], [0.192, 0.167, 0.140])\n",
    "    ])\n",
    "    \n",
    "    model = get_model_for_eval(path_to_weights)\n",
    "    model.to(device)\n",
    "    \n",
    "    images = EsthDataset(paths, transforms=transform)\n",
    "    loader = torch.utils.data.DataLoader(images, batch_size=16, shuffle=False)\n",
    "    \n",
    "    im_names = torch.tensor([], dtype=torch.float, device=device)\n",
    "    y_pred = torch.tensor([], device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader):\n",
    "            inputs = [i.to(device) for i in data[:-1]]\n",
    "            names = data[-1].to(device)\n",
    "\n",
    "            outputs = model(*inputs)\n",
    "            im_names = torch.cat((im_names, names), 0)\n",
    "            y_pred = torch.cat((y_pred, outputs), 0)\n",
    "\n",
    "    y_pred = y_pred.cpu().numpy().flatten()\n",
    "    im_names = im_names.cpu().numpy().flatten().astype(int)\n",
    "            \n",
    "    df = pd.DataFrame({\"image_name\":[paths[i] for i in im_names],\"predicted_score\":y_pred})\n",
    "    df.to_csv(output_path, sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(in_path) for f in filenames if os.path.splitext(f)[1] in ['.png', '.jpg','.jpeg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 22198/22198 [2:30:29<00:00,  2.46it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_batch(files, weights_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
